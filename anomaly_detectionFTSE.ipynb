{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKBPwaSRP8OTwJKN2fDA3v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/01DorSarpong/FTSE_350-anomaly-detection/blob/main/anomaly_detectionFTSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TwoHzV4Q5SBo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing drive model from the google.colab package\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "5hwIf-CV5cVH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting the google drive to a specific path\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD9XRYvt8K5q",
        "outputId": "88ec7b86-8f69-4e3a-e667-1114516a40b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading and saving FTSE 100 stocks\n",
        "\n",
        "#Creating a list of FTSE 100 tickers\n",
        "FTSE100_tickers = [\"AZN.L\", \"HSBA.L\", \"ULVR.L\", \"REL.L\", \"BATS.L\", \"BP.L\", \"GSK.L\", \"DGE.L\",\n",
        "           \"RR.L\", \"NG.L\", \"BARC.L\", \"TSCO.L\", \"PRU.L\", \"BHP.L\", \"BT-A.L\",]\n",
        "\n",
        "\n",
        "# Saving the folder in google drive to store CSVs\n",
        "ftse_100_path = '/content/drive/MyDrive/Colab Notebooks/FTSE 100'\n",
        "os.makedirs(ftse_100_path, exist_ok=True)\n",
        "\n",
        "# Downloading the stocks and saving in folder\n",
        "start_date = \"2014-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "for ticker in tqdm(FTSE100_tickers):\n",
        "    try:\n",
        "        df = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n",
        "        if not df.empty:\n",
        "            df.to_csv(os.path.join(ftse_100_path, f\"{ticker.replace('.L', '')}_2014_2024.csv\"))\n",
        "            print(f\"✅ Saved {ticker}\")\n",
        "        else:\n",
        "            print(f\"⚠️ No data for {ticker}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error downloading {ticker}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl9PbOF4kpiS",
        "outputId": "06568167-d813-4494-9ba3-277fc4b18cea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "  7%|▋         | 1/15 [00:01<00:23,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved AZN.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 13%|█▎        | 2/15 [00:02<00:15,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved HSBA.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 20%|██        | 3/15 [00:03<00:11,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved ULVR.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 27%|██▋       | 4/15 [00:04<00:09,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved REL.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 33%|███▎      | 5/15 [00:04<00:08,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved BATS.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 40%|████      | 6/15 [00:05<00:08,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved BP.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 47%|████▋     | 7/15 [00:06<00:07,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved GSK.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 53%|█████▎    | 8/15 [00:07<00:05,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved DGE.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 60%|██████    | 9/15 [00:08<00:04,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved RR.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 67%|██████▋   | 10/15 [00:09<00:04,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved NG.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 73%|███████▎  | 11/15 [00:09<00:03,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved BARC.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 80%|████████  | 12/15 [00:10<00:02,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved TSCO.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 87%|████████▋ | 13/15 [00:11<00:01,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved PRU.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 93%|█████████▎| 14/15 [00:11<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved BHP.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "100%|██████████| 15/15 [00:13<00:00,  1.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved BT-A.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading and saving FTSE 250 stocks\n",
        "\n",
        "#Creating a list of FTSE 250 tickers\n",
        "FTSE250_tickers = [\"BWY.L\", \"EMG.L\", \"JUST.L\", \"SXS.L\", \"CKN.L\", \"LRE.L\", \"RAT.L\", \"THG.L\",\n",
        "           \"JDW.L\", \"SCT.L\", \"DOM.L\", \"SRE.L\", \"HIK.L\", \"ICGT.L\", \"HSX.L\"]\n",
        "\n",
        "\n",
        "# Saving the folder in google drive to store CSVs\n",
        "ftse_250_path = '/content/drive/MyDrive/Colab Notebooks/FTSE 250'\n",
        "os.makedirs(ftse_250_path, exist_ok=True)\n",
        "\n",
        "# Downloading the stocks and saving in folder\n",
        "start_date = \"2014-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "for ticker in tqdm(FTSE250_tickers):\n",
        "    try:\n",
        "        df = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n",
        "        if not df.empty:\n",
        "            df.to_csv(os.path.join(ftse_250_path, f\"{ticker.replace('.L', '')}_2014_2024.csv\"))\n",
        "            print(f\"✅ Saved {ticker}\")\n",
        "        else:\n",
        "            print(f\"⚠️ No data for {ticker}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error downloading {ticker}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doztt5GNmWbu",
        "outputId": "168550ec-ff9c-4352-8ad5-b10a4648c64d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "  7%|▋         | 1/15 [00:00<00:12,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved BWY.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 13%|█▎        | 2/15 [00:01<00:11,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved EMG.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 20%|██        | 3/15 [00:02<00:09,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved JUST.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 27%|██▋       | 4/15 [00:03<00:07,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved SXS.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 33%|███▎      | 5/15 [00:05<00:13,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved CKN.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 40%|████      | 6/15 [00:06<00:09,  1.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved LRE.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 47%|████▋     | 7/15 [00:06<00:08,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved RAT.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 53%|█████▎    | 8/15 [00:07<00:05,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved THG.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 60%|██████    | 9/15 [00:08<00:04,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved JDW.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 67%|██████▋   | 10/15 [00:08<00:03,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved SCT.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 73%|███████▎  | 11/15 [00:09<00:03,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved DOM.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 80%|████████  | 12/15 [00:10<00:02,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved SRE.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 87%|████████▋ | 13/15 [00:11<00:01,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved HIK.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            " 93%|█████████▎| 14/15 [00:11<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved ICGT.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "100%|██████████| 15/15 [00:12<00:00,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved HSX.L\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inspect one specific file\n",
        "sample_file = 'ULVR_2014_2024.csv'  # you can change this to any file\n",
        "file_path = os.path.join(ftse_100_path, sample_file)\n",
        "\n",
        "# Read the file with second row skipped\n",
        "df = pd.read_csv(file_path, skiprows=[1])\n",
        "\n",
        "# Print the actual column names\n",
        "print(\"Raw column names:\", df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgAgIrQ685Cb",
        "outputId": "b1e40973-0f6c-427e-e346-345ed0791ec8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw column names: ['Price', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load stocks from a folder and build a structured DataFrame\n",
        "def load_stock_data_from_folder(folder_path):\n",
        "    stock_data = {}\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                # Read CSV: use first row as header, skip second row (ticker names)\n",
        "                df = pd.read_csv(file_path, header=0, skiprows=[1], encoding='utf-8-sig')\n",
        "\n",
        "                # Rename the first column to 'Date'\n",
        "                df.rename(columns={df.columns[0]: 'Date'}, inplace=True)\n",
        "\n",
        "                # Normalize column names to lowercase and remove leading/trailing spaces\n",
        "                df.columns = [col.strip().lower() for col in df.columns]\n",
        "\n",
        "                # Clean and prepare the 'date' column\n",
        "                df['date'] = df['date'].astype(str).str.strip()\n",
        "\n",
        "                # Drop any rows where the date column contains the string 'Date'\n",
        "                df = df[df['date'].str.lower() != 'date']\n",
        "\n",
        "                # Convert to datetime\n",
        "                df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "\n",
        "                # Set datetime index\n",
        "                df.set_index('date', inplace=True)\n",
        "\n",
        "                # Drop rows missing essential data (e.g., open price)\n",
        "                if 'open' in df.columns:\n",
        "                    df.dropna(subset=['open'], inplace=True)\n",
        "                else:\n",
        "                    print(f\"⚠️ 'open' column not found in {filename}\")\n",
        "                    continue  # Skip this file\n",
        "\n",
        "                # Extract ticker from filename\n",
        "                ticker = filename.split('_')[0]\n",
        "                stock_data[ticker] = df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error loading {filename}: {type(e).__name__} - {e}\")\n",
        "\n",
        "    return stock_data\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NRA1RMiA8Wu8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ftse100_data = load_stock_data_from_folder(ftse_100_path)\n",
        "ftse250_data = load_stock_data_from_folder(ftse_250_path)\n",
        "#print(f\"Columns for {'ULVR_2014_2024.csv'}:\\n\", df.columns.tolist())\n",
        "print(ftse100_data['ULVR'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfLsnB3WJV1c",
        "outputId": "09141b9b-9353-4560-b9cc-1b0b0bd44cd7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              adj close   close         high          low    open     volume\n",
            "date                                                                        \n",
            "2014-01-02  2426.648438  2436.0  2486.000000  2432.000000  2479.0  1852349.0\n",
            "2014-01-03  2435.613770  2445.0  2453.520020  2434.824951  2449.0  1398177.0\n",
            "2014-01-06  2431.629639  2441.0  2451.000000  2429.000000  2441.0  1432621.0\n",
            "2014-01-07  2433.622314  2443.0  2458.225098  2438.719971  2448.0  1399261.0\n",
            "2014-01-08  2399.752441  2409.0  2450.000000  2402.000000  2449.0  1863248.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-10095474b6d6>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatting stocks to set the business days and fill in gaps\n",
        "\n",
        "# Setting the date index as business days between 2014 and 2024\n",
        "set_weekdays = pd.date_range(start=\"2014-01-01\", end=\"2024-12-31\", freq=\"B\")\n",
        "\n",
        "def format_and_fill(stock_file):\n",
        "    aligned_dict = {}\n",
        "    for ticker, df in stock_file.items():\n",
        "        try:\n",
        "            # Checking that index is datetime\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "\n",
        "            # Reindex to common dates and fill missing values\n",
        "            df_aligned = df.reindex(set_weekdays)\n",
        "            df_filled = df_aligned.ffill().bfill()  # forward-fill then back-fill\n",
        "\n",
        "            aligned_dict[ticker] = df_filled\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error aligning {ticker}: {e}\")\n",
        "    return aligned_dict\n",
        "\n",
        "# Apply to FTSE 100 and 250\n",
        "ftse100_aligned = format_and_fill(ftse100_data)\n",
        "ftse250_aligned = format_and_fill(ftse250_data)\n",
        "\n",
        "#print(ftse250_aligned)\n"
      ],
      "metadata": {
        "id": "wKyfXtZQkFM4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_clear = True\n",
        "\n",
        "for name, df in ftse100_aligned.items():\n",
        "    if df.isna().sum().sum() > 0:\n",
        "        print(f\"❌ Missing values in {name}\")\n",
        "        all_clear = False\n",
        "\n",
        "if all_clear:\n",
        "    print(\"All DataFrames are clean (no missing values)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM5YenjyrQiK",
        "outputId": "6ee2b063-f76e-4810-d12c-882f8f2ca618"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All DataFrames are clean (no missing values)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker, df in ftse100_aligned.items():\n",
        "    print(f\"{ticker} ➤ type: {type(df)} | shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOn88Mya5xBH",
        "outputId": "09fc48dd-3233-46d7-82ea-488cba2bba47"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ULVR ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "DGE ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "AZN ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "NG ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "HSBA ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "REL ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "BP ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "BATS ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "RR ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "GSK ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "BARC ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "TSCO ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "BHP ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "PRU ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n",
            "BT-A ➤ type: <class 'pandas.core.frame.DataFrame'> | shape: (2870, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function that calculates the daily return, rolling mean, std and z-score\n",
        "\n",
        "def add_features(stock_data_dict, window=10):\n",
        "    featured_data = {}\n",
        "\n",
        "    for ticker, df in stock_data_dict.items():\n",
        "        df = df.copy()  # Avoid modifying the original\n",
        "\n",
        "        # Add ticker column for tracking\n",
        "        df[\"ticker\"] = ticker\n",
        "\n",
        "        # Choose the price column: prefer 'adj close', fallback to 'close'\n",
        "        price_col = \"adj close\" if \"adj close\" in df.columns else \"close\"\n",
        "\n",
        "        # Daily return\n",
        "        df[\"daily_return\"] = df[price_col].pct_change()\n",
        "\n",
        "        # Rolling mean and std for price\n",
        "        df[\"rolling_mean\"] = df[price_col].rolling(window=window).mean()\n",
        "        df[\"rolling_std\"] = df[price_col].rolling(window=window).std()\n",
        "\n",
        "        # Z-score of price\n",
        "        df[\"zscore\"] = (df[price_col] - df[\"rolling_mean\"]) / df[\"rolling_std\"]\n",
        "\n",
        "        # Rolling volatility of daily returns\n",
        "        df[\"volatility\"] = df[\"daily_return\"].rolling(window=window).std()\n",
        "\n",
        "        # Drop initial NaN rows (due to rolling calculations)\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        # Store the processed DataFrame\n",
        "        featured_data[ticker] = df\n",
        "\n",
        "    return featured_data\n",
        "\n"
      ],
      "metadata": {
        "id": "bCFIeqF_vy5N"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featured_ftse100 = add_features(ftse100_aligned, window=10)\n",
        "featured_ftse250 = add_features(ftse250_aligned, window=10)\n",
        "\n",
        "print(featured_ftse100['AZN'].head(20))\n",
        "#print(featured_ftse250['DOM'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyiMZVRonEk7",
        "outputId": "a5b361bf-b6e4-4d7b-c854-cc5cbd3c41cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              adj close   close         high          low    open     volume  \\\n",
            "2014-01-15  3830.370117  3845.0  3845.000000  3746.639893  3764.5  3952770.0   \n",
            "2014-01-16  3859.260254  3874.0  3886.500000  3828.000000  3851.0  2673391.0   \n",
            "2014-01-17  3860.256104  3875.0  3912.000000  3854.000000  3895.5  4218589.0   \n",
            "2014-01-20  3905.085205  3920.0  3939.500000  3872.500000  3886.5  2198152.0   \n",
            "2014-01-21  3931.982910  3947.0  3980.979980  3924.500000  3931.0  2875919.0   \n",
            "2014-01-22  3919.032227  3934.0  3963.500000  3911.000000  3947.0  2921981.0   \n",
            "2014-01-23  3944.933105  3960.0  3964.500000  3930.000000  3931.0  2602646.0   \n",
            "2014-01-24  3876.195801  3891.0  3976.483887  3874.500000  3953.0  3344786.0   \n",
            "2014-01-27  3840.830322  3855.5  3917.500000  3846.500000  3890.5  3261022.0   \n",
            "2014-01-28  3850.294434  3865.0  3876.904053  3823.000000  3844.0  3014463.0   \n",
            "2014-01-29  3831.865479  3846.5  3897.000000  3821.500000  3888.5  2548557.0   \n",
            "2014-01-30  3858.264404  3873.0  3878.346924  3833.000000  3855.0  2660157.0   \n",
            "2014-01-31  3843.819336  3858.5  3875.500000  3815.000000  3869.5  2037593.0   \n",
            "2014-02-03  3857.268066  3872.0  3904.500000  3858.500000  3870.5  1996995.0   \n",
            "2014-02-04  3836.347412  3851.0  3875.000000  3832.500000  3865.5  2524868.0   \n",
            "2014-02-05  3862.249268  3877.0  3898.500000  3832.000000  3861.0  2883279.0   \n",
            "2014-02-06  3800.983154  3815.5  3865.500000  3663.704102  3850.5  5586882.0   \n",
            "2014-02-07  3845.312988  3860.0  3865.000000  3824.500000  3845.0  2882044.0   \n",
            "2014-02-10  3900.104492  3915.0  3915.000000  3873.500000  3882.5  2197834.0   \n",
            "2014-02-11  3959.378174  3974.5  3975.000000  3920.399902  3940.0  2963174.0   \n",
            "\n",
            "           ticker  daily_return  rolling_mean  rolling_std    zscore  \\\n",
            "2014-01-15    AZN      0.023832   3620.422510    97.323972  2.157203   \n",
            "2014-01-16    AZN      0.007542   3651.902319   118.608276  1.748259   \n",
            "2014-01-17    AZN      0.000258   3680.742163   131.359598  1.366584   \n",
            "2014-01-20    AZN      0.011613   3712.769824   143.823555  1.337162   \n",
            "2014-01-21    AZN      0.006888   3751.073560   146.329598  1.236314   \n",
            "2014-01-22    AZN     -0.003294   3789.377246   133.329550  0.972440   \n",
            "2014-01-23    AZN      0.006609   3827.979810   113.612719  1.029403   \n",
            "2014-01-24    AZN     -0.017424   3851.788916    92.360496  0.264257   \n",
            "2014-01-27    AZN     -0.009124   3870.915747    59.944571 -0.501887   \n",
            "2014-01-28    AZN      0.002464   3881.824048    40.486324 -0.778772   \n",
            "2014-01-29    AZN     -0.004786   3881.973584    40.277385 -1.244075   \n",
            "2014-01-30    AZN      0.006889   3881.873999    40.340964 -0.585251   \n",
            "2014-01-31    AZN     -0.003744   3880.230322    41.633784 -0.874554   \n",
            "2014-02-03    AZN      0.003499   3875.448608    41.205717 -0.441214   \n",
            "2014-02-04    AZN     -0.005424   3865.885059    37.563814 -0.786332   \n",
            "2014-02-05    AZN      0.006752   3860.206763    32.601173  0.062651   \n",
            "2014-02-06    AZN     -0.015863   3845.811768    20.608122 -2.175289   \n",
            "2014-02-07    AZN      0.011663   3842.723486    17.650737  0.146708   \n",
            "2014-02-10    AZN      0.014249   3848.650903    25.257760  2.037140   \n",
            "2014-02-11    AZN      0.015198   3859.559277    43.217140  2.309706   \n",
            "\n",
            "            volatility  \n",
            "2014-01-15    0.012089  \n",
            "2014-01-16    0.011776  \n",
            "2014-01-17    0.012071  \n",
            "2014-01-20    0.012024  \n",
            "2014-01-21    0.010152  \n",
            "2014-01-22    0.010098  \n",
            "2014-01-23    0.010092  \n",
            "2014-01-24    0.012439  \n",
            "2014-01-27    0.013369  \n",
            "2014-01-28    0.011394  \n",
            "2014-01-29    0.008879  \n",
            "2014-01-30    0.008820  \n",
            "2014-01-31    0.008898  \n",
            "2014-02-03    0.008007  \n",
            "2014-02-04    0.007559  \n",
            "2014-02-05    0.008082  \n",
            "2014-02-06    0.008699  \n",
            "2014-02-07    0.008451  \n",
            "2014-02-10    0.009091  \n",
            "2014-02-11    0.010069  \n"
          ]
        }
      ]
    }
  ]
}