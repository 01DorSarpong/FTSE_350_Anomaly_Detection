{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7jN0d3qJZZK","outputId":"8c212ba9-4495-47f5-86cb-bed8bc3cf4dc","executionInfo":{"status":"ok","timestamp":1750021346493,"user_tz":-60,"elapsed":20985,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Importing drive model from the google.colab package\n","from google.colab import drive\n","\n","#Mounting the google drive to a specific path\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/GitHub_Projects/FTSE_350_Anomaly_Detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_8kLZ9NLAgy","outputId":"60a9fe25-2a8d-4592-dd47-59d977301e07","executionInfo":{"status":"ok","timestamp":1750021352982,"user_tz":-60,"elapsed":371,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/GitHub_Projects/FTSE_350_Anomaly_Detection\n"]}]},{"cell_type":"code","source":["# Configuring Git user details\n","!git config --global user.email \"dorothy.sarpongk@gmail.com\"\n","!git config --global user.name \"01DorSarpong\""],"metadata":{"id":"sdbbjCzE0tWT","executionInfo":{"status":"ok","timestamp":1750021357749,"user_tz":-60,"elapsed":1011,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Importing libraries for code\n","\n","import pandas as pd\n","import numpy  as np\n","import yfinance as yf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","from tqdm import tqdm\n"],"metadata":{"id":"jQ_wBKNkmV25","executionInfo":{"status":"ok","timestamp":1750021366683,"user_tz":-60,"elapsed":4761,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def download_and_save_FTSE_stocks(tickers: list, start_date: str, end_date: str, directory: str):\n","  \"\"\"\n","  This function downloads historical stock data for a list of tickers and saves it to CSV files.\n","\n","  Args:\n","    tickers_list (list): A list of stock ticker symbols (e.g., ['TSCO.L', 'BARC.L']).\n","    start_date (str): The start date for data download in 'YYYY-MM-DD' format.\n","    end_date (str): The end date for data download in 'YYYY-MM-DD' format.\n","    directory (str): The path to the directory where CSV files will be saved.\n","  \"\"\"\n","\n","  # Ensure the save directory exists\n","  if not os.path.exists(directory):\n","    os.makedirs(directory)\n","    print(f\"Created directory: {directory}\")\n","\n","  print(f\"Starting download for {len(tickers)} tickers from {start_date} to {end_date}...\")\n","\n","  for ticker in tqdm(tickers, desc=\"Downloading Stocks\"):\n","    # Format the filename: remove '.L' and add date range for clarity\n","    cleaned_ticker = ticker.replace('.L', '')\n","    file_name = f\"{cleaned_ticker}_{start_date.replace('-', '')}_{end_date.replace('-', '')}.csv\"\n","    full_file_path = os.path.join(directory, file_name)\n","\n","    try:\n","      df = yf.download(ticker, start=start_date, end=end_date, auto_adjust=False)\n","\n","      if not df.empty:\n","        df.to_csv(full_file_path)\n","        # print(f\"✅ Saved data for {ticker} to {full_file_path}\") # Optional: uncomment for more verbose output\n","      else:\n","        print(f\"⚠️ No data available for {ticker} for the specified period.\")\n","    except Exception as e:\n","      print(f\"❌ Error downloading or saving data for {ticker}: {e}\")\n","\n","  print(\"Download process completed.\")\n"],"metadata":{"id":"6Iby76j7PtZR","executionInfo":{"status":"ok","timestamp":1750021374095,"user_tz":-60,"elapsed":4,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Creating a list of FTSE 100 and FTSE 250 tickers\n","\n","FTSE_100_tickers = [\"AZN.L\", \"HSBA.L\", \"ULVR.L\", \"REL.L\", \"BATS.L\", \"BP.L\", \"GSK.L\", \"DGE.L\",\n","                   \"RR.L\", \"NG.L\", \"BARC.L\", \"TSCO.L\", \"PRU.L\", \"BHP.L\", \"BT-A.L\",]\n","\n","FTSE_250_tickers = [\"BWY.L\", \"EMG.L\", \"JUST.L\", \"SXS.L\", \"CKN.L\", \"LRE.L\", \"RAT.L\", \"THG.L\",\n","                    \"JDW.L\", \"SCT.L\", \"DOM.L\", \"SRE.L\", \"HIK.L\", \"ICGT.L\", \"HSX.L\"]"],"metadata":{"id":"2L4EdTEsuCu8","executionInfo":{"status":"ok","timestamp":1750021398301,"user_tz":-60,"elapsed":4,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Defining the period for stocks range\n","start_date = \"2014-01-01\"\n","end_date = \"2024-12-31\""],"metadata":{"id":"yESfV6rzUuQ1","executionInfo":{"status":"ok","timestamp":1750021407829,"user_tz":-60,"elapsed":5,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Defining the path to save the CSVs\n","\n","ftse_100_path = '/content/drive/MyDrive/GitHub_Projects/FTSE_350_Anomaly_Detection/FTSE_100'\n","ftse_250_path = '/content/drive/MyDrive/GitHub_Projects/FTSE_350_Anomaly_Detection/FTSE_250'\n"],"metadata":{"id":"w9mFm0wLVH6v","executionInfo":{"status":"ok","timestamp":1750021410791,"user_tz":-60,"elapsed":4,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Calling the function for FTSE 100 and FTSE 250 tickers\n","\n","download_and_save_FTSE_stocks(\n","    tickers=FTSE_100_tickers,\n","    start_date=start_date,\n","    end_date=end_date,\n","    directory=ftse_100_path\n",")\n","\n","download_and_save_FTSE_stocks(\n","    tickers=FTSE_250_tickers,\n","    start_date=start_date,\n","    end_date=end_date,\n","    directory=ftse_250_path\n",")"],"metadata":{"id":"dnZIuB7oXMSA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating a function to load stocks and pre-process into a dataframe\n","\n","def load_and_structure_stock_data(folder_path: str) -> pd.DataFrame:\n","    \"\"\"\n","    Loads historical stock data from CSV files in a specified folder,\n","    cleans, processes, filters to weekdays, fills NaNs/gaps, and\n","    consolidates them into a single structured DataFrame with a MultiIndex.\n","\n","    Args:\n","        folder_path (str): The path to the directory containing stock data CSVs.\n","\n","    Returns:\n","        pd.DataFrame: A single DataFrame containing data for all tickers,\n","                      indexed by 'Date' and 'Ticker', sorted by Date and then Ticker.\n","                      Returns an empty DataFrame if no data is loaded or processed.\n","    \"\"\"\n","    all_dfs = []\n","\n","    if not os.path.exists(folder_path):\n","        print(f\"❌ Error: Folder not found at {folder_path}\")\n","        return pd.DataFrame() # Return empty DataFrame if folder doesn't exist\n","\n","    # Get list of CSV files to process\n","    file_list = [f.name for f in os.scandir(folder_path) if f.name.endswith(\".csv\")]\n","\n","    if not file_list:\n","        print(f\"⚠️ No CSV files found in {folder_path}\")\n","        return pd.DataFrame()\n","\n","    print(f\"Loading and processing data from {len(file_list)} CSV files in {folder_path}...\")\n","\n","    # Define columns that typically contain numerical stock data to be filled\n","    numerical_cols_to_fill = ['open', 'high', 'low', 'close', 'adj close', 'volume']\n","\n","    for filename in tqdm(file_list, desc=\"Processing Stock Files\"):\n","        file_path = os.path.join(folder_path, filename)\n","\n","        try:\n","            # Read CSV: use first row as header, skip second row (often contains ticker name repeated)\n","            df = pd.read_csv(file_path, header=0, skiprows=[1], encoding='utf-8-sig')\n","\n","            # --- Initial Cleaning and Date Conversion ---\n","            # Rename the first column to 'Date' if it's not already\n","            if df.columns[0].strip().lower() != 'date':\n","                df.rename(columns={df.columns[0]: 'Date'}, inplace=True)\n","\n","            # Normalize all column names to lowercase and remove leading/trailing spaces\n","            df.columns = [col.strip().lower() for col in df.columns]\n","\n","            # Clean and prepare the 'date' column\n","            df['date'] = df['date'].astype(str).str.strip()\n","            df = df[df['date'].str.lower() != 'date'] # Drop any rows where the date column contains the string 'Date'\n","\n","            # Convert to datetime, coercing errors will turn unparseable dates into NaT\n","            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n","            df.dropna(subset=['date'], inplace=True) # Drop rows where date conversion failed (NaT)\n","\n","            # --- Add Ticker Information ---\n","            # Extract ticker from filename (e.g., 'TSCO_20140101_20241231.csv' -> 'TSCO')\n","            ticker_symbol = filename.split('_')[0]\n","            df['ticker'] = ticker_symbol\n","\n","            # --- Set Date as Index (temporarily for filtering/filling) ---\n","            df.set_index('date', inplace=True)\n","\n","            # --- Filter for Weekdays Only ---\n","            # .dayofweek returns Monday=0, ..., Sunday=6. Keep only 0 to 4.\n","            df = df[df.index.dayofweek < 5]\n","\n","            # --- Fill NaNs/Gaps for Numerical Columns ---\n","            # Identify columns to fill that actually exist in the current DataFrame\n","            existing_numerical_cols = [col for col in numerical_cols_to_fill if col in df.columns]\n","\n","            if not existing_numerical_cols:\n","                # print(f\"⚠️ No numerical columns found for {filename}. Skipping NaN filling for this file.\")\n","                pass # This is fine, just means the file might only have non-numerical data or very specific columns\n","\n","            # Apply forward-fill then backward-fill for numerical columns within this ticker's data\n","            # This handles gaps for individual stock series\n","            df[existing_numerical_cols] = df[existing_numerical_cols].ffill().bfill()\n","\n","            # --- Final Check for essential data after filling ---\n","            # If 'open' column is vital and still has NaNs (e.g., entire series was NaN), drop those rows\n","            if 'open' in df.columns:\n","                df.dropna(subset=['open'], inplace=True)\n","            else:\n","                print(f\"⚠️ 'open' column not found in {filename}. Skipping this file as essential data is missing.\")\n","                continue # Skip this file if 'open' is genuinely missing\n","\n","            if df.empty:\n","                print(f\"⚠️ No valid weekday data remaining for {filename} after filtering. Skipping.\")\n","                continue\n","\n","            all_dfs.append(df)\n","\n","        except pd.errors.EmptyDataError:\n","            print(f\"⚠️ {filename} is empty. Skipping.\")\n","        except pd.errors.ParserError as e:\n","            print(f\"❌ Error parsing {filename}: {type(e).__name__} - {e}. Skipping.\")\n","        except Exception as e:\n","            print(f\"❌ Error processing {filename}: {type(e).__name__} - {e}. Skipping.\")\n","\n","    if not all_dfs:\n","        print(\"No valid stock data loaded after processing. Returning empty DataFrame.\")\n","        return pd.DataFrame()\n","\n","    # --- Consolidate all DataFrames into one structured DataFrame ---\n","    combined_df = pd.concat(all_dfs)\n","\n","    # Set a MultiIndex: primary index is 'Date', secondary is 'ticker'\n","    # 'ticker' was added as a regular column inside the loop, now it becomes part of the index\n","    combined_df.set_index('ticker', append=True, inplace=True)\n","    combined_df.index.names = ['Date', 'Ticker']\n","\n","    # Sort the MultiIndex for better performance and consistency\n","    combined_df.sort_index(inplace=True)\n","\n","    print(\"All stock data loaded, structured, filtered, and filled successfully.\")\n","    return combined_df\n","\n"],"metadata":{"id":"oQt_Z87EH2L9","executionInfo":{"status":"ok","timestamp":1750021570346,"user_tz":-60,"elapsed":6,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Calling the function for FTSE 100 stocks\n","\n","ready_ftse100_data = load_and_structure_stock_data(ftse_100_path)\n","\n","if not ready_ftse100_data.empty:\n","  print(\"\\n--- Final Structured and Cleaned DataFrame ---\")\n","  print(ready_ftse100_data.head(15)) # Show more rows to see multiple dates/tickers\n","  print(\"\\nDataFrame Info:\")\n","  ready_ftse100_data.info()\n","  print(\"\\nSample of weekdays (should only be Mon-Fri):\")\n","  print(ready_ftse100_data.index.get_level_values('Date').day_name().value_counts())\n","  print(\"\\nNaNs after processing (should be very few or none in numerical columns):\")\n","  print(ready_ftse100_data.isnull().sum())\n","else:\n"," print(\"No data was successfully loaded and processed.\")"],"metadata":{"id":"gK9gOL3vIK_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calling the function for FTSE 250 stocks\n","\n","ready_ftse250_data = load_and_structure_stock_data(ftse_250_path)\n","\n","if not ready_ftse250_data.empty:\n","  print(\"\\n--- Final Structured and Cleaned DataFrame ---\")\n","  print(ready_ftse250_data.head(15)) # Show more rows to see multiple dates/tickers\n","  print(\"\\nDataFrame Info:\")\n","  ready_ftse250_data.info()\n","  print(\"\\nSample of weekdays (should only be Mon-Fri):\")\n","  print(ready_ftse250_data.index.get_level_values('Date').day_name().value_counts())\n","  print(\"\\nNaNs after processing (should be very few or none in numerical columns):\")\n","  print(ready_ftse250_data.isnull().sum())\n","else:\n"," print(\"No data was successfully loaded and processed.\")"],"metadata":{"id":"XktAAHheAscj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A function to genereate the stock features needed to build ML model\n","\n","def generate_all_stock_features(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Generates a comprehensive set of time-series and cross-sectional numerical features\n","    for stock data, suitable for unsupervised anomaly detection models.\n","\n","    This function assumes the input DataFrame has a MultiIndex (Date, Ticker)\n","    and contains cleaned base columns like 'open', 'high', 'low', 'close',\n","    'adj close', and 'volume', with no critical NaNs.\n","\n","    Args:\n","        df (pd.DataFrame): Your clean DataFrame with MultiIndex (Date, Ticker)\n","                           and base stock price/volume data.\n","\n","    Returns:\n","        pd.DataFrame: The DataFrame with all original and newly engineered numerical\n","                      features. NaNs introduced by calculations (e.g., at the start\n","                      of rolling windows) will be present.\n","    \"\"\"\n","    if df.empty:\n","        print(\"Input DataFrame is empty for feature generation. Returning empty DataFrame.\")\n","        return pd.DataFrame()\n","\n","    processed_df = df.copy() # Always work on a copy to keep the original untouched\n","\n","    # --- Ensure critical columns are numerical for calculations ---\n","    for col in ['open', 'high', 'low', 'close', 'adj close', 'volume']:\n","        if col in processed_df.columns:\n","            processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')\n","    processed_df.dropna(subset=['open', 'close', 'volume'], inplace=True)\n","    if processed_df.empty:\n","        print(\"No data remaining after ensuring essential columns are numerical and not NaN.\")\n","        return pd.DataFrame()\n","\n","\n","    grouped_by_ticker = processed_df.groupby(level='Ticker')\n","    grouped_by_date = processed_df.groupby(level='Date')\n","    epsilon = 1e-9\n","\n","    print(\"Generating Time-Series Based Features (per stock ticker)...\")\n","\n","    # 1. Return-Based Features:\n","    processed_df['log_return'] = grouped_by_ticker['close'].transform(\n","        lambda x: np.log(x / x.shift(1).replace(0, epsilon)).replace([-np.inf, np.inf], np.nan)\n","    )\n","    processed_df['simple_return'] = grouped_by_ticker['close'].transform(\n","        lambda x: (x / x.shift(1).replace(0, epsilon)) - 1\n","    )\n","    if 'adj close' in processed_df.columns:\n","        processed_df['log_adj_close_return'] = grouped_by_ticker['adj close'].transform(\n","            lambda x: np.log(x / x.shift(1).replace(0, epsilon)).replace([-np.inf, np.inf], np.nan)\n","        )\n","    processed_df['return_5d'] = grouped_by_ticker['close'].transform(lambda x: x.pct_change(periods=5))\n","    processed_df['return_20d'] = grouped_by_ticker['close'].transform(lambda x: x.pct_change(periods=20))\n","\n","    print(\"Generating Volatility Measures...\")\n","    # 2. Volatility Measures:\n","    processed_df['rolling_std_5d_log_return'] = grouped_by_ticker['log_return'].transform(lambda x: x.rolling(window=5).std())\n","    processed_df['rolling_std_20d_log_return'] = grouped_by_ticker['log_return'].transform(lambda x: x.rolling(window=20).std())\n","\n","    if 'high' in processed_df.columns and 'low' in processed_df.columns:\n","        processed_df['daily_range_norm'] = (processed_df['high'] - processed_df['low']) / (processed_df['close'] + epsilon)\n","\n","        # Garman-Klass Volatility: Careful handling of log and sqrt\n","        log_high_div_low = np.log((processed_df['high'] / processed_df['low'].replace(0, epsilon)).clip(lower=epsilon))\n","        log_close_div_open = np.log((processed_df['close'] / processed_df['open'].replace(0, epsilon)).clip(lower=epsilon))\n","\n","        gk_term = 0.5 * (log_high_div_low)**2 - (2 * np.log(2) - 1) * (log_close_div_open)**2\n","        # Handle cases where the term inside sqrt might be negative due to floating point or weird data\n","        gk_term[gk_term < 0] = np.nan\n","        processed_df['garman_klass_vol'] = np.sqrt(gk_term)\n","\n","        # Clean up potential infs/NaNs from result and fill explicitly\n","        processed_df['garman_klass_vol'] = processed_df['garman_klass_vol'].replace([-np.inf, np.inf], np.nan)\n","        processed_df['garman_klass_vol'].fillna(0, inplace=True) # Using inplace here is fine on a single column\n","    else:\n","        print(\"⚠️ Missing 'high' or 'low' columns for some volatility features. Skipping.\")\n","\n","    print(\"Generating Volume-Based Features...\")\n","    # 3. Volume-Based Features:\n","    processed_df['volume_change'] = grouped_by_ticker['volume'].transform(lambda x: x.pct_change(periods=1))\n","    processed_df['avg_volume_20d'] = grouped_by_ticker['volume'].transform(lambda x: x.rolling(window=20).mean())\n","    processed_df['relative_volume'] = processed_df['volume'] / (processed_df['avg_volume_20d'] + epsilon)\n","\n","    print(\"Generating Momentum/Trend Indicators...\")\n","    # 4. Momentum/Trend Indicators:\n","    processed_df['sma_5d'] = grouped_by_ticker['close'].transform(lambda x: x.rolling(window=5).mean())\n","    processed_df['sma_20d'] = grouped_by_ticker['close'].transform(lambda x: x.rolling(window=20).mean())\n","    processed_df['deviation_from_sma_20d'] = (processed_df['close'] - processed_df['sma_20d']) / (processed_df['sma_20d'] + epsilon)\n","\n","    print(\"Generating Price-Volume Interaction Features...\")\n","    # 5. Price-Volume Interaction Features:\n","    if 'high' in processed_df.columns and 'low' in processed_df.columns:\n","        processed_df['typical_price'] = (processed_df['high'] + processed_df['low'] + processed_df['close']) / 3\n","    else:\n","        print(\"⚠️ Missing 'high' or 'low' columns. Skipping 'typical_price'.\")\n","\n","    print(\"Generating Cross-Sectional Features (comparing stocks on the same day)...\")\n","    # 6. Cross-Sectional Features:\n","    if 'log_return' in processed_df.columns:\n","        processed_df['daily_market_mean_log_return'] = grouped_by_date['log_return'].transform('mean')\n","        processed_df['daily_market_median_log_return'] = grouped_by_date['log_return'].transform('median')\n","\n","        processed_df['deviation_from_daily_mean_return'] = processed_df['log_return'] - processed_df['daily_market_mean_log_return']\n","        processed_df['deviation_from_daily_median_return'] = processed_df['log_return'] - processed_df['daily_market_median_log_return']\n","        processed_df['daily_return_rank_pct'] = grouped_by_date['log_return'].rank(pct=True, method='average')\n","    else:\n","        print(\"⚠️ 'log_return' column not available for cross-sectional feature generation. Skipping these features.\")\n","\n","    print(\"Feature generation complete. NaNs from calculations are present and will need further handling.\")\n","    return processed_df.sort_index()\n"],"metadata":{"id":"CX47oDUYDIPX","executionInfo":{"status":"ok","timestamp":1750027295004,"user_tz":-60,"elapsed":33,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","# Call the feature generation function\n","\n","df_with_all_features = generate_all_stock_features(ready_ftse100_data)\n","\n","if not df_with_all_features.empty:\n","    print(\"\\n--- NEWLY GENERATED DataFrame with ALL Engineered Features (Head) ---\")\n","    # To ensure you see all columns, even if there are many:\n","    pd.set_option('display.max_columns', None) # Display all columns\n","    pd.set_option('display.width', 1000)      # Ensure wide display in terminal/Colab output\n","\n","    # Now, print the head of the *NEW* DataFrame\n","    print(df_with_all_features.head(15))\n","\n","    print(\"\\n--- NEWLY GENERATED DataFrame Info (should show many more columns) ---\")\n","    # Now, print the info of the *NEW* DataFrame\n","    df_with_all_features.info()\n","\n","    print(\"\\n--- ALL Column Names in the NEW DataFrame ---\")\n","    # This will explicitly list ALL column names, proving they are there\n","    print(df_with_all_features.columns.tolist())\n","\n","    print(\"\\n--- Count of NaNs per column (expect some NaNs from rolling/shifting, esp. at start of series) ---\")\n","    print(df_with_all_features.isnull().sum().sort_values(ascending=False).head(20))\n","else:\n","    print(\"The feature generation function returned an empty DataFrame.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNB55xrl1RAx","executionInfo":{"status":"ok","timestamp":1750028642452,"user_tz":-60,"elapsed":242,"user":{"displayName":"dorothy sarpong","userId":"04133103870765976145"}},"outputId":"3181614a-bc26-47b6-e298-142527734a14"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating Time-Series Based Features (per stock ticker)...\n","Generating Volatility Measures...\n","Generating Volume-Based Features...\n","Generating Momentum/Trend Indicators...\n","Generating Price-Volume Interaction Features...\n","Generating Cross-Sectional Features (comparing stocks on the same day)...\n","Feature generation complete. NaNs from calculations are present and will need further handling.\n","\n","--- NEWLY GENERATED DataFrame with ALL Engineered Features (Head) ---\n","                     adj close        close         high          low         open      volume  log_return  simple_return  log_adj_close_return  return_5d  return_20d  rolling_std_5d_log_return  rolling_std_20d_log_return  daily_range_norm  garman_klass_vol  volume_change  avg_volume_20d  relative_volume  sma_5d  sma_20d  deviation_from_sma_20d  typical_price  daily_market_mean_log_return  daily_market_median_log_return  deviation_from_daily_mean_return  deviation_from_daily_median_return  daily_return_rank_pct\n","Date       Ticker                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n","2014-01-02 AZN     3544.462402  3558.000000  3592.500000  3545.500000  3566.000000   1966575.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.013210          0.009207            NaN             NaN              NaN     NaN      NaN                     NaN    3565.333333                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           BARC     270.183716   271.049988   274.651001   268.350006   273.000000  30563664.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.023247          0.015795            NaN             NaN              NaN     NaN      NaN                     NaN     271.350332                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           BATS    3185.132568  3207.500000  3252.500000  3207.000000  3252.500000   2054699.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.014186          0.004925            NaN             NaN              NaN     NaN      NaN                     NaN    3222.333333                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           BHP     1839.356567  1852.000000  1877.000000  1835.000000  1877.000000   5062171.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.022678          0.013661            NaN             NaN              NaN     NaN      NaN                     NaN    1854.666667                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           BP       485.792603   488.850006   490.950012   484.649994   490.950012  17484921.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.012887          0.008735            NaN             NaN              NaN     NaN      NaN                     NaN     488.150004                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           BT-A     378.285370   380.100006   383.299988   376.899994   380.200012  11554147.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.016838          0.011905            NaN             NaN              NaN     NaN      NaN                     NaN     380.099996                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           DGE     1978.450562  1984.000000  2010.500000  1977.500000  2008.500000   3652686.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.016633          0.008875            NaN             NaN              NaN     NaN      NaN                     NaN    1990.666667                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           GSK     1600.524902  1611.268677  1628.393677  1609.253906  1628.393677   3761631.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.011879          0.005169            NaN             NaN              NaN     NaN      NaN                     NaN    1616.305420                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           HSBA     655.954834   659.700012   661.200012   654.599976   658.400024  15181957.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.010005          0.006987            NaN             NaN              NaN     NaN      NaN                     NaN     658.500000                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           NG       857.661316   859.635986   864.545105   853.635986   859.635986   2146883.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.012690          0.008979            NaN             NaN              NaN     NaN      NaN                     NaN     859.272359                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           PRU     1110.276855  1113.241699  1128.979492  1106.615356  1118.211548   4084796.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.020089          0.013874            NaN             NaN              NaN     NaN      NaN                     NaN    1116.278849                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           REL      899.564697   902.000000   903.000000   892.500000   896.500000   2172875.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.011641          0.007345            NaN             NaN              NaN     NaN      NaN                     NaN     899.166667                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           RR       434.293518   434.450897   438.445404   432.621796   438.225708   5188161.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.013405          0.007777            NaN             NaN              NaN     NaN      NaN                     NaN     435.172699                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           TSCO     416.419128   418.063110   428.259796   415.783112   425.029785  11736686.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.029844          0.018209            NaN             NaN              NaN     NaN      NaN                     NaN     420.702006                           NaN                             NaN                               NaN                                 NaN                    NaN\n","           ULVR    2426.648682  2436.000000  2486.000000  2432.000000  2479.000000   1852349.0         NaN            NaN                   NaN        NaN         NaN                        NaN                         NaN          0.022167          0.011085            NaN             NaN              NaN     NaN      NaN                     NaN    2451.333333                           NaN                             NaN                               NaN                                 NaN                    NaN\n","\n","--- NEWLY GENERATED DataFrame Info (should show many more columns) ---\n","<class 'pandas.core.frame.DataFrame'>\n","MultiIndex: 41669 entries, (Timestamp('2014-01-02 00:00:00'), 'AZN') to (Timestamp('2024-12-30 00:00:00'), 'ULVR')\n","Data columns (total 27 columns):\n"," #   Column                              Non-Null Count  Dtype  \n","---  ------                              --------------  -----  \n"," 0   adj close                           41669 non-null  float64\n"," 1   close                               41669 non-null  float64\n"," 2   high                                41669 non-null  float64\n"," 3   low                                 41669 non-null  float64\n"," 4   open                                41669 non-null  float64\n"," 5   volume                              41669 non-null  float64\n"," 6   log_return                          41654 non-null  float64\n"," 7   simple_return                       41654 non-null  float64\n"," 8   log_adj_close_return                41654 non-null  float64\n"," 9   return_5d                           41594 non-null  float64\n"," 10  return_20d                          41369 non-null  float64\n"," 11  rolling_std_5d_log_return           41594 non-null  float64\n"," 12  rolling_std_20d_log_return          41369 non-null  float64\n"," 13  daily_range_norm                    41669 non-null  float64\n"," 14  garman_klass_vol                    41669 non-null  float64\n"," 15  volume_change                       41654 non-null  float64\n"," 16  avg_volume_20d                      41384 non-null  float64\n"," 17  relative_volume                     41384 non-null  float64\n"," 18  sma_5d                              41609 non-null  float64\n"," 19  sma_20d                             41384 non-null  float64\n"," 20  deviation_from_sma_20d              41384 non-null  float64\n"," 21  typical_price                       41669 non-null  float64\n"," 22  daily_market_mean_log_return        41654 non-null  float64\n"," 23  daily_market_median_log_return      41654 non-null  float64\n"," 24  deviation_from_daily_mean_return    41654 non-null  float64\n"," 25  deviation_from_daily_median_return  41654 non-null  float64\n"," 26  daily_return_rank_pct               41654 non-null  float64\n","dtypes: float64(27)\n","memory usage: 8.8+ MB\n","\n","--- ALL Column Names in the NEW DataFrame ---\n","['adj close', 'close', 'high', 'low', 'open', 'volume', 'log_return', 'simple_return', 'log_adj_close_return', 'return_5d', 'return_20d', 'rolling_std_5d_log_return', 'rolling_std_20d_log_return', 'daily_range_norm', 'garman_klass_vol', 'volume_change', 'avg_volume_20d', 'relative_volume', 'sma_5d', 'sma_20d', 'deviation_from_sma_20d', 'typical_price', 'daily_market_mean_log_return', 'daily_market_median_log_return', 'deviation_from_daily_mean_return', 'deviation_from_daily_median_return', 'daily_return_rank_pct']\n","\n","--- Count of NaNs per column (expect some NaNs from rolling/shifting, esp. at start of series) ---\n","return_20d                            300\n","rolling_std_20d_log_return            300\n","avg_volume_20d                        285\n","sma_20d                               285\n","relative_volume                       285\n","deviation_from_sma_20d                285\n","rolling_std_5d_log_return              75\n","return_5d                              75\n","sma_5d                                 60\n","simple_return                          15\n","log_return                             15\n","deviation_from_daily_median_return     15\n","deviation_from_daily_mean_return       15\n","daily_market_mean_log_return           15\n","daily_market_median_log_return         15\n","daily_return_rank_pct                  15\n","volume_change                          15\n","log_adj_close_return                   15\n","adj close                               0\n","open                                    0\n","dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-22-1062250618>:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  processed_df['garman_klass_vol'].fillna(0, inplace=True) # Using inplace here is fine on a single column\n"]}]}]}